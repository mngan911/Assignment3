{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Final"
      ],
      "metadata": {
        "id": "tmypBbKbuzIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Simulate Data**\n",
        "* First, we simulate the AR(1) errors by producing functions in use."
      ],
      "metadata": {
        "id": "o1XV76JWzGi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "def simulate_ar1(n, phi, sigma):\n",
        "  errors = np.zeros(n)\n",
        "  eta = np.random.normal(0, sigma, n)  # white noise\n",
        "  for t in range(1, n):\n",
        "    errors[t] = phi * errors[t - 1] + eta[t]\n",
        "  return errors\n",
        "\n",
        "def simulate_regression_with_ar1_errors(n, beta0, beta1, phi_x, phi_u, sigma):\n",
        "  x = simulate_ar1(n, phi_x, sigma)\n",
        "  u = simulate_ar1(n, phi_u, sigma)\n",
        "  y = beta0 + beta1 * x + u\n",
        "  return x, y, u"
      ],
      "metadata": {
        "id": "9edsnMbfuzID"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in Time Series, the data is serially correlated, therefore the use of white standard errors will not be effective (tested in Appendix sections below). Therefore, we introduce only the HAC standard errors and performe Monte Carlo on it."
      ],
      "metadata": {
        "id": "6KS3dw9Lw_Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Substituting data to conduct Monte Carlo\n",
        "np.random.seed(0) # Set random seed for reproducibility\n",
        "\n",
        "beta0 = 1.          # Intercept\n",
        "beta1 = 2           # Slope\n",
        "phi_x = 0.7         # AR(1) coefficient for x\n",
        "phi_u = 0.7         # AR(1) coefficient for the errors\n",
        "sigma = 1           # Standard deviation of the white noise\n",
        "\n",
        "# Simulating the model\n",
        "## Do monte carlo\n",
        "\n",
        "def Monte_Carlo(T):\n",
        "  t_stats_hac = []\n",
        "  mean_beta_1 = []\n",
        "  for i in range(10000):\n",
        "    x, y, errors = simulate_regression_with_ar1_errors(T, beta0, beta1, phi_x, phi_u, sigma)\n",
        "    X = sm.add_constant(x)\n",
        "        ## Use HAC: takes into account serial correlation\n",
        "    model_1 = sm.OLS(y, X).fit(cov_type='HAC', cov_kwds={'maxlags': np.floor(1.3*T**(1/2)).astype(int)})\n",
        "    t_stats_hac.append(model_1.t_test('x1=2').tvalue)\n",
        "  # Check we reject the null hypothesis at alpha=0.05 about 5% of the time\n",
        "  print(f\"Monte Carlo T = {T}\", f\"Empirical size test beta_1=2 using HAC SE: {np.mean(np.abs(np.array(t_stats_hac)) > 1.965)}\")\n",
        "  print(f\"Mean Beta_1: {np.mean(model_1.params[[1]])}\")\n",
        "\n",
        "Monte_Carlo(T=100)\n",
        "Monte_Carlo(T=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c7c574-9cea-4fc3-eaf2-beb1b12a1a96",
        "id": "ioQ0MIzNuzID"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monte Carlo T = 100 Empirical size test beta_1=2 using HAC SE: 0.1605\n",
            "Mean Beta_1: 2.0884267642491903\n",
            "Monte Carlo T = 500 Empirical size test beta_1=2 using HAC SE: 0.0814\n",
            "Mean Beta_1: 2.0026284349478223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Calculate bootstrap standard errors**"
      ],
      "metadata": {
        "id": "UlZSXnAQ1jyU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we increase T, the result get closer to 5% (at 0.08), also the Mean get closer to True value . Now we use Bootstrap resampling to calculate standard errors.\n",
        "* Assuming Time Series, the data is dependent (data from Jan-Dec should be all taken into consideration, can't omit Feb in between). Therefore, we use Moving Block Bootstrap (MBB).\n",
        "\n",
        "* We first define the MBB func by setting the way to calculate the number of blocks, taking bootstrap samples, bootstrap estimates >>> Then conduct the MBB, taking the length of block as 12 (L=12, one block containing data from 12 consecutive months)."
      ],
      "metadata": {
        "id": "f3Pzh4qyuzID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def moving_block_bootstrap(x, y, L, num_bootstrap): # L is block length\n",
        "  np.random.seed(0)\n",
        "  T = len(y)  # Total number of observations\n",
        "  num_blocks = T // L + (1 if T % L else 0)\n",
        "\n",
        "  # Fit the original model\n",
        "  X = sm.add_constant(x)\n",
        "  original_model = sm.OLS(y, X)\n",
        "  original_results = original_model.fit()\n",
        "\n",
        "  bootstrap_estimates = np.zeros((num_bootstrap, 2))  # Storing estimates for beta_0 and beta_1\n",
        "\n",
        "  # Perform the bootstrap\n",
        "  for i in range(num_bootstrap):\n",
        "    # Create bootstrap sample\n",
        "    bootstrap_indices = np.random.choice(np.arange(num_blocks) * L, size=num_blocks, replace=True)  # Randomly select block indices from arrays\n",
        "    bootstrap_sample_indices = np.hstack([np.arange(index, min(index + L, T)) for index in bootstrap_indices])\n",
        "    bootstrap_sample_indices = bootstrap_sample_indices[:T]  # Ensure the bootstrap sample is the same size as the original data\n",
        "\n",
        "    x_bootstrap = x[bootstrap_sample_indices]\n",
        "    y_bootstrap = y[bootstrap_sample_indices]\n",
        "\n",
        "    # Refit the model on bootstrap sample\n",
        "    X_bootstrap = sm.add_constant(x_bootstrap)\n",
        "    bootstrap_model = sm.OLS(y_bootstrap, X_bootstrap)\n",
        "    bootstrap_results = bootstrap_model.fit()\n",
        "\n",
        "    # Store the estimates\n",
        "    bootstrap_estimates[i, :] = bootstrap_results.params\n",
        "\n",
        "    return bootstrap_estimates\n",
        "    return np.mean(bootstrap_results.params[1])\n",
        "\n",
        "# Run moving block bootstrap\n",
        "block_length = 12 # For example: 1 block containing 12 months\n",
        "num_bootstrap = 1000 # Set the number of Bootstrap\n",
        "\n",
        "for T in [100, 500]:\n",
        "  np.random.seed(0)\n",
        "  x, y, errors = simulate_regression_with_ar1_errors(T, beta0, beta1, phi_x, phi_u, sigma)\n",
        "  bootstrap_results = moving_block_bootstrap(x, y, block_length, num_bootstrap)\n",
        "\n",
        "    # Calculate and print standard errors\n",
        "  bootstrap_se_T = bootstrap_results.std(axis=0)\n",
        "  print(\"Bootstrap Standard Errors,\", f\"T={T}\")\n",
        "  print(\"SE(beta_0):\", bootstrap_se_T[0])\n",
        "  print(\"SE(beta_1):\", bootstrap_se_T[1])\n",
        "\n",
        "    ## Theoretical se from OLS\n",
        "  X = sm.add_constant(x)\n",
        "  model = sm.OLS(y, X)\n",
        "  results = model.fit()\n",
        "\n",
        "    # Standard errors from statsmodels\n",
        "  statsmodels_se = results.bse\n",
        "  print(\"\\nStandard Errors from statsmodels OLS,\", f\"T={T}\")\n",
        "  print(\"SE(beta_0):\", statsmodels_se[0])\n",
        "  print(\"SE(beta_1):\", statsmodels_se[1])\n",
        "  print(\"--\" * 20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b12e12-1b81-4081-c369-46436d5f4711",
        "id": "NULiPQDLuzIE"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap Standard Errors, T=100\n",
            "SE(beta_0): 0.03611711758325965\n",
            "SE(beta_1): 0.06156310761596185\n",
            "\n",
            "Standard Errors from statsmodels OLS, T=100\n",
            "SE(beta_0): 0.1526466299523327\n",
            "SE(beta_1): 0.09805991113020616\n",
            "----------------------------------------\n",
            "Bootstrap Standard Errors, T=500\n",
            "SE(beta_0): 0.02120655314287504\n",
            "SE(beta_1): 0.058421314817626836\n",
            "\n",
            "Standard Errors from statsmodels OLS, T=500\n",
            "SE(beta_0): 0.05899727253364852\n",
            "SE(beta_1): 0.041274753055842404\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result seems to make sense as:\n",
        "* Bootstrap standard errors decrease as the number of Bootstrap increase (tested before between 1000 and 10000).\n",
        "* Also when the number of T in Monte Carlo increase, the standard errors decrease, showing the improve in accuracy."
      ],
      "metadata": {
        "id": "K7TtuyzeuzIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Construct a 95% confidence interval for Beta_1 using both the bootstrap and the theoretical standard errors.**"
      ],
      "metadata": {
        "id": "twgq6ddtGdRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def theoretical_se (T):\n",
        "  np.random.seed(0)\n",
        "  for i in range(1000):\n",
        "    x, y, errors = simulate_regression_with_ar1_errors(T, beta0, beta1, phi_x, phi_u, sigma)\n",
        "    X = sm.add_constant(x)\n",
        "    model = sm.OLS(y, X)\n",
        "    results = model.fit()\n",
        "  return results.bse[1]"
      ],
      "metadata": {
        "id": "gDslXfPTSXUO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate 95% confidence interval for beta_1\n",
        "# Using Theoretical se\n",
        "beta_1_mean = [2.088, 2.003] #Taking beta_1 mean from the first simulation part\n",
        "ci_lower_100 = beta_1_mean[0] - 1.96 * theoretical_se (100)\n",
        "ci_upper_100 = beta_1_mean[0] + 1.96 * theoretical_se (100)\n",
        "\n",
        "ci_lower_500 = beta_1_mean[1] - 1.96 * theoretical_se (500)\n",
        "ci_upper_500 = beta_1_mean[1] + 1.96 * theoretical_se (500)\n",
        "\n",
        "print(f\"T = 100\", \"95% Confidence Interval for beta_1:\")\n",
        "print(f\"[{ci_lower_100:.4f}, {ci_upper_100:.4f}]\\n\")\n",
        "\n",
        "print(f\"T = 500\", \"95% Confidence Interval for beta_1:\")\n",
        "print(f\"[{ci_lower_500:.4f}, {ci_upper_500:.4f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d57ef33-6413-43a4-ea2f-237737e02dda",
        "id": "FKuBPJhAuzIE"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T = 100 95% Confidence Interval for beta_1:\n",
            "[1.9119, 2.2641]\n",
            "\n",
            "T = 500 95% Confidence Interval for beta_1:\n",
            "[1.9170, 2.0890]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking CI and empirical coverage\n",
        "# Set parameters\n",
        "np.random.seed(0)\n",
        "beta_0_true = 1\n",
        "beta_1_true = 2\n",
        "sigma = 1\n",
        "num_simulations = 10000\n",
        "\n",
        "# Arrays to store the estimates from each simulation\n",
        "def CI_and_coverage(T):\n",
        "  beta_0_estimates = np.zeros(num_simulations)\n",
        "  beta_1_estimates = np.zeros(num_simulations)\n",
        "  beta_0_in = np.zeros(num_simulations)\n",
        "  beta_1_in = np.zeros(num_simulations)\n",
        "\n",
        "# Run simulations\n",
        "  for i in range(num_simulations):\n",
        "    x = np.random.standard_cauchy(T)\n",
        "    u = np.random.standard_cauchy(T)\n",
        "    y = beta_0_true + beta_1_true * x + u\n",
        "    # OLS estimation\n",
        "    X = np.vstack([np.ones(T), x]).T\n",
        "    XXinv = np.linalg.inv(X.T @ X)\n",
        "    beta_hat = XXinv @ X.T @ y\n",
        "    beta_0_estimates[i] = beta_hat[0]\n",
        "    beta_1_estimates[i] = beta_hat[1]\n",
        "    u_hat = y - beta_hat[0] - beta_hat[1] * x\n",
        "    sigma2_hat = np.dot(u_hat, u_hat)/(T-2)\n",
        "    variance_hat = sigma2_hat*XXinv\n",
        "    se_0 = np.sqrt(variance_hat[0,0])\n",
        "    se_1 = np.sqrt(variance_hat[1,1])\n",
        "      ## Check whether beta_1 in CI 95%\n",
        "    beta_1_in[i] = beta_hat[1] - 1.965*se_1 < beta_1_true < beta_hat[1] + 1.965*se_1\n",
        "  print(f\"Monte Carlo T = {T}\")\n",
        "  print(\"95% Confidence Interval for beta_1:\", f\"[{beta_hat[1] - 1.965*se_1:.4f}, {beta_hat[1] + 1.965*se_1:.4f}]\")\n",
        "  print(f\"The empirical 95% CI coverage for beta_1: {np.mean(beta_1_in)}\\n\") #Taking the proportion of True value, or beta_1_true is in the confidence interval\n",
        "\n",
        "# Output the results\n",
        "CI_and_coverage(T=100)\n",
        "CI_and_coverage(T=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1101ca0-d31b-434a-8d9c-c886e2a2358f",
        "id": "6-xlJj_6uzIF"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monte Carlo T = 100\n",
            "95% Confidence Interval for beta_1: [1.6458, 2.3239]\n",
            "The empirical 95% CI coverage for beta_1: 0.9507\n",
            "\n",
            "Monte Carlo T = 500\n",
            "95% Confidence Interval for beta_1: [1.8317, 2.1556]\n",
            "The empirical 95% CI coverage for beta_1: 0.9715\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result seems to match the concept, as increasing simulation from 100 to 500 will increase coverage for Beta_1, showing the improvement."
      ],
      "metadata": {
        "id": "Eg4bikqCuzIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The team will try to improve the assignment more â™¥"
      ],
      "metadata": {
        "id": "OPKrTis6o88O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix."
      ],
      "metadata": {
        "id": "wEcPNMMJAuIP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm3FTMWHpqc6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "def simulate_ar1(n, phi, sigma):\n",
        "  \"\"\"\n",
        "  Simulate an AR(1) process.\n",
        "\n",
        "  Parameters:\n",
        "  n (int): Number of observations.\n",
        "  phi (float): Coefficient of AR(1) process.\n",
        "  sigma (float): Standard deviation of the innovation term.\n",
        "\n",
        "  Returns:\n",
        "  np.array: Simulated AR(1) error terms.\n",
        "  \"\"\"\n",
        "  errors = np.zeros(n)\n",
        "  eta = np.random.normal(0, sigma, n)  # white noise\n",
        "  for t in range(1, n):\n",
        "    errors[t] = phi * errors[t - 1] + eta[t]\n",
        "  return errors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_regression_with_ar1_errors(n, beta0, beta1, phi_x, phi_u, sigma):\n",
        "  \"\"\"\n",
        "  Simulate a regression model with AR(1) error terms.\n",
        "  Parameters:\n",
        "    n (int): Number of observations.\n",
        "    beta0 (float): Intercept of the regression model.\n",
        "    beta1 (float): Slope of the regression model.\n",
        "    phi (float): Coefficient of the AR(1) process in the error term.\n",
        "    sigma (float): Standard deviation of the innovation term in the AR(1) process.\n",
        "    Returns:\n",
        "  tuple: x (independent variable), y (dependent variable), errors (AR(1) process)\n",
        "  \"\"\"\n",
        "  x = simulate_ar1(n, phi_x, sigma)\n",
        "  u = simulate_ar1(n, phi_u, sigma)\n",
        "  y = beta0 + beta1 * x + u\n",
        "  return x, y, u"
      ],
      "metadata": {
        "id": "ENVhWsxbqKFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Substituing data\n",
        "T = 500              # Number of observations\n",
        "beta0 = 1.           # Intercept\n",
        "beta1 = 2           # Slope\n",
        "phi_x = 0.7             # AR(1) coefficient for x\n",
        "phi_u = 0.7             # AR(1) coefficient for the errors\n",
        "sigma = 1             # Standard deviation of the white noise\n",
        "\n",
        "# Simulating the model\n",
        "\n",
        "## Do monte carlo to find both white se and HAC se\n",
        "t_stats_hc = []\n",
        "t_stats_hac = []\n",
        "\n",
        "for i in range(1000):\n",
        "  x, y, errors = simulate_regression_with_ar1_errors(T, beta0, beta1, phi_x, phi_u, sigma)\n",
        "  X = sm.add_constant(x)\n",
        "  model = sm.OLS(y, X).fit(cov_type='HC1')\n",
        "  t_stats_hc.append(model.t_test('x1=2').tvalue)\n",
        "     ## Use HAC: takes into account serial correlation\n",
        "  model2 = sm.OLS(y, X).fit(cov_type='HAC', cov_kwds={'maxlags': np.floor(1.3*T**(1/2)).astype(int)})\n",
        "  t_stats_hac.append(model2.t_test('x1=2').tvalue)\n",
        "\n",
        "## Check we reject the null hypothesis at alpha=0.05 about 5% of the time\n",
        "\n",
        "print(f\"Empirical size test beta_1=2 using White SE: {np.mean(np.abs(np.array(t_stats_hc)) > 1.965)}\")\n",
        "print(f\"Empirical size test beta_1=2 using HAC SE: {np.mean(np.abs(np.array(t_stats_hac)) > 1.965)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdNHjHxrqM1g",
        "outputId": "7ec8efe1-58b9-43f1-ec74-8df2c978bdcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empirical size test beta_1=2 using White SE: 0.25\n",
            "Empirical size test beta_1=2 using HAC SE: 0.088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " This would suggest that the White standard errors are not adequately accounting for the autocorrelation in the errors.\n",
        "\n",
        " The HAC standard errors, though being 0.09 - almost double the 5%, is performing better, as it takes into account the serial correlation. By increasing the Bootstrap sample size, we might get a closer number to 5%."
      ],
      "metadata": {
        "id": "OJMGygEr2ME-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Other notes:**\n",
        "* Monte Carlo: Math tools - simulate and describe exactly the probability distribution of the output Z. When knows exactly how the data is generated, given the parameters of the model.\n",
        "\n",
        "  Only use when you can draw many sample of size T.\n",
        "\n",
        "* Bootstrap: Simulate on sample instead of population, resampling repetitively (draw n times with replacement). Using empirical distribution F^ as a replacement for the true distribution.\n",
        "\n",
        "  Use when you can't access to the whole population.\n",
        "\n"
      ],
      "metadata": {
        "id": "YTsmrSaKeZWI"
      }
    }
  ]
}